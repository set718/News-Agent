"""
åŸºäºLangchainçš„å·¥ä½œæµé“¾
é‡æ„åŸæœ‰åŠŸèƒ½ä¸ºæ ‡å‡†çš„Langchain Chainæ¶æ„
"""
import time
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta

from langchain.chains.base import Chain
from langchain.memory import SimpleMemory
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from pydantic import BaseModel, Field

from email_fetcher import EmailFetcher
from data_storage import db_manager, NewsArticle
from config import (
    DEEPSEEK_API_KEY, 
    DEEPSEEK_BASE_URL, 
    CONTENT_FILTER_PROMPT,
    LANGCHAIN_BATCH_SIZE,
    LANGCHAIN_MAX_TOKENS,
    LANGCHAIN_TEMPERATURE
)


class FilterResult(BaseModel):
    """ç­›é€‰ç»“æœçš„Pydanticæ¨¡å‹"""
    is_selected: bool = Field(description="æ˜¯å¦é€šè¿‡ç­›é€‰")
    quality_score: float = Field(description="è´¨é‡è¯„åˆ†(1-10)", ge=1, le=10)
    relevance_score: float = Field(description="ç›¸å…³æ€§è¯„åˆ†(1-10)", ge=1, le=10)
    reason: str = Field(description="ç­›é€‰ç†ç”±")
    key_points: List[str] = Field(description="å…³é”®è¦ç‚¹", default=[])
    category: str = Field(description="æ–‡ç« åˆ†ç±»")


class EmailFetchChain(Chain):
    """é‚®ä»¶è·å–é“¾ - è´Ÿè´£è·å–å’Œè§£æGoogle Alerté‚®ä»¶"""
    
    input_key: str = "days"
    output_key: str = "emails"
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.email_fetcher = EmailFetcher()
    
    @property
    def input_keys(self) -> List[str]:
        return [self.input_key]
    
    @property
    def output_keys(self) -> List[str]:
        return [self.output_key]
    
    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé‚®ä»¶è·å–"""
        days = inputs.get(self.input_key, 1)
        
        print(f"\n{'='*50}")
        print(f"ğŸ”„ Chain 1: è·å–æœ€è¿‘ {days} å¤©çš„ Google Alert é‚®ä»¶")
        print(f"{'='*50}")
        
        try:
            # è·å–é‚®ä»¶
            alert_emails = self.email_fetcher.fetch_google_alerts(days=days)
            
            if not alert_emails:
                print("æ²¡æœ‰æ‰¾åˆ°æ–°çš„Google Alerté‚®ä»¶")
                return {self.output_key: []}
            
            # å­˜å‚¨é‚®ä»¶å’Œæ–‡ç« 
            total_new_articles = 0
            stored_emails = []
            
            for email in alert_emails:
                # ä¿å­˜é‚®ä»¶
                saved_email = db_manager.save_alert_email({
                    'message_id': email.message_id,
                    'subject': email.subject,
                    'sender': email.sender,
                    'date': email.date,
                    'body_html': email.body_html,
                    'body_text': email.body_text
                })
                
                if saved_email and email.articles:
                    # ä¸ºæ–‡ç« æ·»åŠ é‚®ä»¶ID
                    for article in email.articles:
                        article['email_message_id'] = email.message_id
                    
                    # ä¿å­˜æ–‡ç« 
                    saved_articles = db_manager.save_articles(email.articles)
                    total_new_articles += len(saved_articles)
                    stored_emails.append(email)
            
            print(f"âœ… é‚®ä»¶è·å–å®Œæˆ: {len(stored_emails)} å°é‚®ä»¶, {total_new_articles} ç¯‡æ–°æ–‡ç« ")
            return {self.output_key: stored_emails}
            
        except Exception as e:
            print(f"âŒ é‚®ä»¶è·å–å¤±è´¥: {e}")
            return {self.output_key: []}


class ArticleFilterChain(Chain):
    """æ–‡ç« ç­›é€‰é“¾ - ä½¿ç”¨LLMè¿›è¡Œå†…å®¹ç­›é€‰"""
    
    input_key: str = "limit"
    output_key: str = "filter_stats"
    
    def __init__(self, batch_size: int = None, **kwargs):
        super().__init__(**kwargs)
        
        self.batch_size = batch_size or LANGCHAIN_BATCH_SIZE
        
        # åˆå§‹åŒ–LLMï¼Œå¢åŠ max_tokensä»¥æ”¯æŒæ‰¹é‡å¤„ç†
        self.llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=DEEPSEEK_API_KEY,
            openai_api_base=DEEPSEEK_BASE_URL,
            temperature=LANGCHAIN_TEMPERATURE,
            max_tokens=LANGCHAIN_MAX_TOKENS
        )
        
        # åˆ›å»ºæ‰¹é‡ç­›é€‰çš„æç¤ºæ¨¡æ¿
        self.batch_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»å†…å®¹åˆ†æå¸ˆï¼Œè´Ÿè´£è¯„ä¼°å’Œç­›é€‰æ–°é—»æ–‡ç« çš„è´¨é‡å’Œç›¸å…³æ€§ã€‚

ç›®æ ‡ç”¨æˆ·ï¼šæ±½è½¦è¡Œä¸šåˆ¶é€ å·¥ç¨‹å¸ˆ
å…³æ³¨é¢†åŸŸï¼šæ±½è½¦å·¥å‚å»ºè®¾ã€AIæŠ€æœ¯ã€å…ˆè¿›åˆ¶é€ æŠ€æœ¯

ç­›é€‰æ ‡å‡†ï¼š
1. ä¼˜å…ˆä¿ç•™ï¼š
   - æ±½è½¦å·¥å‚å»ºè®¾ã€æ‰©å»ºã€æŠ€æœ¯å‡çº§ç›¸å…³
   - æ±½è½¦åˆ¶é€ æµç¨‹ã€ç”Ÿäº§çº¿ã€è´¨é‡æ§åˆ¶
   - å¯åº”ç”¨äºæ±½è½¦å·¥å‚çš„AIæŠ€æœ¯ï¼ˆå·¥ä¸šæœºå™¨äººã€æœºå™¨è§†è§‰ã€æ•°å­—å­ªç”Ÿã€é¢„æµ‹æ€§ç»´æŠ¤ç­‰ï¼‰
   - å…ˆè¿›åˆ¶é€ æŠ€æœ¯ï¼ˆå¢æåˆ¶é€ /3Dæ‰“å°ã€è‡ªåŠ¨åŒ–ã€æ™ºèƒ½åˆ¶é€ ã€å·¥ä¸š4.0ç­‰ï¼‰
   - æ±½è½¦ä¾›åº”é“¾ã€ææ–™æŠ€æœ¯ã€æ–°èƒ½æºæ±½è½¦åˆ¶é€ 

2. ä¿ç•™ä½†é™ä½ä¼˜å…ˆçº§ï¼š
   - é€šç”¨åˆ¶é€ æŠ€æœ¯ï¼ˆå¦‚æœå¯åº”ç”¨äºæ±½è½¦å·¥å‚ï¼‰
   - å…¶ä»–è¡Œä¸šçš„å…ˆè¿›åˆ¶é€ æ¡ˆä¾‹ï¼ˆå¦‚æœæŠ€æœ¯å¯å€Ÿé‰´ï¼‰

3. æ˜ç¡®å‰”é™¤ï¼š
   - æ”¿æ²»ã€ç¤¾ä¼šã€å¨±ä¹æ–°é—»
   - ä»…æ¶‰åŠéæ±½è½¦è¡Œä¸šåˆ¶é€ çš„å†…å®¹
   - æ±½è½¦é”€å”®ã€å¸‚åœºè¥é”€ã€é‡‘èæŠ•èµ„ç±»æ–°é—»
   - ä¸åˆ¶é€ å·¥ç¨‹æ— å…³çš„æ±½è½¦æ–°é—»ï¼ˆå¦‚è½¦å‹å‘å¸ƒã€æµ‹è¯„ç­‰ï¼‰

è¯·åˆ†æä»¥ä¸‹ {num_articles} ç¯‡æ–°é—»ï¼Œå¹¶å¯¹æ¯ç¯‡æ–‡ç« è¿”å›ç­›é€‰ç»“æœï¼š

{articles_content}

è¯·è¿”å›ä¸€ä¸ªJSONæ•°ç»„ï¼ŒåŒ…å« {num_articles} ä¸ªç­›é€‰ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
    {{
        "is_selected": true/false,
        "quality_score": 1-10çš„è¯„åˆ†ï¼ˆå†…å®¹æ·±åº¦å’Œä»·å€¼ï¼‰,
        "relevance_score": 1-10çš„è¯„åˆ†ï¼ˆä¸æ±½è½¦åˆ¶é€ å·¥ç¨‹çš„ç›¸å…³æ€§ï¼‰,
        "reason": "è¯¦ç»†çš„ç­›é€‰ç†ç”±ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©æˆ–æ‹’ç»",
        "key_points": ["æå–çš„å…³é”®æŠ€æœ¯è¦ç‚¹æˆ–åˆ¶é€ ä¿¡æ¯"],
        "category": "åˆ†ç±»ï¼šæ±½è½¦å·¥å‚å»ºè®¾/AIåˆ¶é€ æŠ€æœ¯/å…ˆè¿›åˆ¶é€ /ä¾›åº”é“¾æŠ€æœ¯/å…¶ä»–"
    }},
    ...
]""",
            input_variables=["num_articles", "articles_content"]
        )
        
        # æ„å»ºæ‰¹é‡ç­›é€‰é“¾
        self.batch_filter_chain = (
            self.batch_prompt 
            | self.llm 
            | StrOutputParser()
        )
    
    @property
    def input_keys(self) -> List[str]:
        return [self.input_key]
    
    @property
    def output_keys(self) -> List[str]:
        return [self.output_key]
    
    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ–‡ç« ç­›é€‰ï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        limit = inputs.get(self.input_key, 50)
        
        print(f"\n{'='*50}")
        print(f"ğŸ¤– Chain 2: ä½¿ç”¨ LLM æ‰¹é‡ç­›é€‰æ–‡ç« å†…å®¹")
        print(f"{'='*50}")
        
        # è·å–æœªç­›é€‰çš„æ–‡ç« 
        unfiltered_articles = db_manager.get_unfiltered_articles(limit=limit)
        
        if not unfiltered_articles:
            print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç­›é€‰çš„æ–‡ç« ")
            return {self.output_key: {'total': 0, 'processed': 0, 'selected': 0, 'rejected': 0, 'failed': 0}}
        
        print(f"å¼€å§‹æ‰¹é‡ç­›é€‰ {len(unfiltered_articles)} ç¯‡æ–‡ç«  (æ‰¹å¤„ç†å¤§å°: {self.batch_size})...")
        
        stats = {
            'total': len(unfiltered_articles),
            'processed': 0,
            'selected': 0,
            'rejected': 0,
            'failed': 0
        }
        
        # æŒ‰æ‰¹æ¬¡å¤„ç†æ–‡ç« 
        for batch_start in range(0, len(unfiltered_articles), self.batch_size):
            batch_end = min(batch_start + self.batch_size, len(unfiltered_articles))
            batch_articles = unfiltered_articles[batch_start:batch_end]
            
            print(f"å¤„ç†æ‰¹æ¬¡ {batch_start//self.batch_size + 1}: æ–‡ç«  {batch_start+1}-{batch_end}")
            
            try:
                # æ‰¹é‡ç­›é€‰è¿™ç»„æ–‡ç« 
                batch_results = self._batch_filter_articles(batch_articles)
                
                # å¤„ç†ç»“æœ
                for i, (article, result) in enumerate(zip(batch_articles, batch_results)):
                    if result:
                        # æ›´æ–°æ•°æ®åº“
                        success = db_manager.update_article_filter_result(article.id, result)
                        if success:
                            stats['processed'] += 1
                            if result.get('is_selected'):
                                stats['selected'] += 1
                                print(f"  âœ“ æ–‡ç«  {batch_start+i+1}: é€šè¿‡")
                            else:
                                stats['rejected'] += 1
                                print(f"  âœ— æ–‡ç«  {batch_start+i+1}: æœªé€šè¿‡")
                        else:
                            stats['failed'] += 1
                            print(f"  âš  æ–‡ç«  {batch_start+i+1}: æ•°æ®åº“æ›´æ–°å¤±è´¥")
                    else:
                        stats['failed'] += 1
                        print(f"  âš  æ–‡ç«  {batch_start+i+1}: ç­›é€‰å¤±è´¥")
                
            except Exception as e:
                print(f"  âŒ æ‰¹æ¬¡ç­›é€‰å¤±è´¥: {e}")
                # å¦‚æœæ‰¹æ¬¡å¤±è´¥ï¼Œæ ‡è®°è¿™æ‰¹æ¬¡æ‰€æœ‰æ–‡ç« ä¸ºå¤±è´¥
                stats['failed'] += len(batch_articles)
            
            # æ‰¹æ¬¡é—´çŸ­æš‚å»¶è¿Ÿ
            if batch_end < len(unfiltered_articles):
                time.sleep(0.5)
        
        print(f"\nâœ… ç­›é€‰å®Œæˆ:")
        print(f"  - æ€»è®¡: {stats['total']}")
        print(f"  - æˆåŠŸå¤„ç†: {stats['processed']}")
        print(f"  - ç­›é€‰é€šè¿‡: {stats['selected']}")
        print(f"  - ç­›é€‰æœªé€šè¿‡: {stats['rejected']}")
        print(f"  - å¤„ç†å¤±è´¥: {stats['failed']}")
        
        return {self.output_key: stats}

    def _batch_filter_articles(self, articles: List[NewsArticle]) -> List[Optional[Dict]]:
        """æ‰¹é‡ç­›é€‰æ–‡ç« """
        try:
            # æ„å»ºæ–‡ç« å†…å®¹
            articles_content = ""
            for i, article in enumerate(articles, 1):
                articles_content += f"""
æ–‡ç«  {i}:
æ ‡é¢˜ï¼š{article.title}
æ¥æºï¼š{article.source or "æœªçŸ¥æ¥æº"}
å†…å®¹æ‘˜è¦ï¼š{article.summary or "æ— æ‘˜è¦"}
å‘å¸ƒæ—¶é—´ï¼š{article.publish_time or "æœªçŸ¥æ—¶é—´"}
åŸæ–‡é“¾æ¥ï¼š{article.url[:100] + "..." if len(article.url) > 100 else article.url}

"""
            
            # è°ƒç”¨æ‰¹é‡ç­›é€‰é“¾
            response = self.batch_filter_chain.invoke({
                "num_articles": len(articles),
                "articles_content": articles_content.strip()
            })
            
            # è§£æå“åº”
            return self._parse_batch_response(response, len(articles))
            
        except Exception as e:
            print(f"æ‰¹é‡ç­›é€‰é“¾è°ƒç”¨å¤±è´¥: {e}")
            return [None] * len(articles)

    def _parse_batch_response(self, response: str, expected_count: int) -> List[Optional[Dict]]:
        """è§£ææ‰¹é‡APIå“åº”"""
        try:
            import json
            
            # å°è¯•æå–JSONæ•°ç»„
            response = response.strip()
            
            # æŸ¥æ‰¾JSONæ•°ç»„å¼€å§‹å’Œç»“æŸä½ç½®
            start_idx = response.find('[')
            end_idx = response.rfind(']') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_str = response[start_idx:end_idx]
                results = json.loads(json_str)
                
                if not isinstance(results, list):
                    print(f"å“åº”ä¸æ˜¯JSONæ•°ç»„æ ¼å¼")
                    return [None] * expected_count
                
                # éªŒè¯ç»“æœæ•°é‡
                if len(results) != expected_count:
                    print(f"å“åº”æ•°é‡ä¸åŒ¹é…ï¼šæœŸæœ› {expected_count}ï¼Œå®é™… {len(results)}")
                    # è°ƒæ•´ç»“æœæ•°é‡
                    if len(results) < expected_count:
                        results.extend([None] * (expected_count - len(results)))
                    else:
                        results = results[:expected_count]
                
                # éªŒè¯å’Œæ¸…ç†æ¯ä¸ªç»“æœ
                cleaned_results = []
                for i, result in enumerate(results):
                    if result and isinstance(result, dict):
                        # éªŒè¯å¿…éœ€å­—æ®µ
                        required_fields = ['is_selected', 'quality_score', 'relevance_score', 'reason']
                        if all(field in result for field in required_fields):
                            # ç¡®ä¿åˆ†æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
                            result['quality_score'] = max(1, min(10, float(result.get('quality_score', 5))))
                            result['relevance_score'] = max(1, min(10, float(result.get('relevance_score', 5))))
                            # ç¡®ä¿key_pointsæ˜¯åˆ—è¡¨
                            if 'key_points' not in result:
                                result['key_points'] = []
                            elif not isinstance(result['key_points'], list):
                                result['key_points'] = [str(result['key_points'])]
                            # ç¡®ä¿categoryå­˜åœ¨
                            if 'category' not in result:
                                result['category'] = 'å…¶ä»–'
                            
                            cleaned_results.append(result)
                        else:
                            print(f"æ–‡ç«  {i+1} å“åº”ç¼ºå°‘å¿…éœ€å­—æ®µ: {result}")
                            cleaned_results.append(None)
                    else:
                        print(f"æ–‡ç«  {i+1} å“åº”æ ¼å¼é”™è¯¯")
                        cleaned_results.append(None)
                
                return cleaned_results
            else:
                print(f"æ— æ³•æ‰¾åˆ°æœ‰æ•ˆJSONæ•°ç»„: {response[:200]}...")
                return [None] * expected_count
                
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response[:500]}...")
            return [None] * expected_count
        except Exception as e:
            print(f"è§£ææ‰¹é‡å“åº”æ—¶å‡ºé”™: {e}")
            return [None] * expected_count


class ReportGenerationChain(Chain):
    """æŠ¥å‘Šç”Ÿæˆé“¾ - ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    
    input_key: str = "days"
    output_key: str = "report"
    
    @property
    def input_keys(self) -> List[str]:
        return [self.input_key]
    
    @property
    def output_keys(self) -> List[str]:
        return [self.output_key]
    
    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆæŠ¥å‘Š"""
        days = inputs.get(self.input_key, 1)
        
        print(f"\n{'='*50}")
        print(f"ğŸ“Š Chain 3: ç”Ÿæˆç­›é€‰æŠ¥å‘Š")
        print(f"{'='*50}")
        
        try:
            # è·å–æ•°æ®åº“ç»Ÿè®¡
            stats = db_manager.get_statistics()
            
            print(f"æ•°æ®åº“ç»Ÿè®¡:")
            print(f"  - æ€»é‚®ä»¶æ•°: {stats['total_emails']}")
            print(f"  - æ€»æ–‡ç« æ•°: {stats['total_articles']}")
            print(f"  - å·²ç­›é€‰: {stats['filtered_articles']}")
            print(f"  - ç­›é€‰é€šè¿‡: {stats['selected_articles']}")
            
            # è·å–ç­›é€‰é€šè¿‡çš„æ–‡ç« 
            selected_articles = db_manager.get_selected_articles(days=days)
            
            if not selected_articles:
                report = f"æœ€è¿‘ {days} å¤©æ²¡æœ‰ç­›é€‰é€šè¿‡çš„æ–‡ç« ã€‚"
                return {self.output_key: report}
            
            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            report = self._generate_detailed_report(selected_articles, days)
            
            print("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return {self.output_key: report}
            
        except Exception as e:
            print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return {self.output_key: ""}
    
    def _generate_detailed_report(self, articles, days: int) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        # ç»Ÿè®¡åˆ†æ
        source_stats = {}
        category_stats = {}
        quality_scores = []
        relevance_scores = []
        
        for article in articles:
            # æ¥æºç»Ÿè®¡
            source = article.source or "æœªçŸ¥æ¥æº"
            source_stats[source] = source_stats.get(source, 0) + 1
            
            # ç±»åˆ«ç»Ÿè®¡
            if article.category:
                category_stats[article.category] = category_stats.get(article.category, 0) + 1
            
            # åˆ†æ•°æ”¶é›†
            if article.quality_score:
                quality_scores.append(article.quality_score)
            if article.relevance_score:
                relevance_scores.append(article.relevance_score)
        
        # è®¡ç®—å¹³å‡åˆ†
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        avg_relevance = sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""
æœ€è¿‘ {days} å¤©ç­›é€‰æŠ¥å‘Š
{'='*50}

æ€»ä½“ç»Ÿè®¡:
- ç­›é€‰é€šè¿‡æ–‡ç« : {len(articles)} ç¯‡
- å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.1f}/10
- å¹³å‡ç›¸å…³æ€§è¯„åˆ†: {avg_relevance:.1f}/10

æ¥æºåˆ†å¸ƒ:
"""
        
        # æ·»åŠ æ¥æºç»Ÿè®¡
        for source, count in sorted(source_stats.items(), key=lambda x: x[1], reverse=True):
            report += f"- {source}: {count} ç¯‡\n"
        
        # æ·»åŠ ç±»åˆ«ç»Ÿè®¡
        if category_stats:
            report += "\nç±»åˆ«åˆ†å¸ƒ:\n"
            for category, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
                report += f"- {category}: {count} ç¯‡\n"
        
        # æ·»åŠ é«˜è´¨é‡æ–‡ç« æ¨è
        top_articles = sorted(articles, 
                            key=lambda x: (x.quality_score or 0) + (x.relevance_score or 0), 
                            reverse=True)[:5]
        
        if top_articles:
            report += "\næ¨èé˜…è¯» (Top 5):\n"
            for i, article in enumerate(top_articles, 1):
                report += f"{i}. {article.title}\n"
                report += f"   æ¥æº: {article.source} | è´¨é‡: {article.quality_score:.1f} | ç›¸å…³æ€§: {article.relevance_score:.1f}\n"
                report += f"   é“¾æ¥: {article.url}\n\n"
        
        return report


class NewsProcessingWorkflow:
    """æ–°é—»å¤„ç†å·¥ä½œæµ - ç»„åˆå¤šä¸ªChain"""
    
    def __init__(self):
        # åˆå§‹åŒ–å„ä¸ªé“¾
        self.email_chain = EmailFetchChain()
        self.filter_chain = ArticleFilterChain()
        self.report_chain = ReportGenerationChain()
        
        # åˆå§‹åŒ–å†…å­˜
        self.memory = SimpleMemory()
    
    def run_full_workflow(self, days: int = 1, filter_limit: int = 50) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å·¥ä½œæµç¨‹"""
        print(f"ğŸš€ Google Alert å¤„ç†å·¥ä½œæµç¨‹å¯åŠ¨ (Langchainæ¶æ„)")
        print(f"ğŸ“… å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # åˆ›å»ºå·¥ä½œæµè¾“å…¥
        workflow_input = {
            "days": days,
            "limit": filter_limit,
            "timestamp": datetime.now()
        }
        
        # å­˜å‚¨åˆ°å†…å­˜
        self.memory.save_context(
            {"input": workflow_input},
            {"status": "started"}
        )
        
        try:
            # æ­¥éª¤1: è·å–é‚®ä»¶
            email_result = self.email_chain({"days": days})
            emails = email_result["emails"]
            
            # æ­¥éª¤2: ç­›é€‰æ–‡ç« 
            filter_result = self.filter_chain({"limit": filter_limit})
            filter_stats = filter_result["filter_stats"]
            
            # æ­¥éª¤3: ç”ŸæˆæŠ¥å‘Š
            report_result = self.report_chain({"days": days})
            report = report_result["report"]
            
            # æœ€ç»ˆç»“æœ
            result = {
                'emails_processed': len(emails),
                'filter_stats': filter_stats,
                'report': report,
                'workflow_status': 'completed'
            }
            
            # å­˜å‚¨ç»“æœåˆ°å†…å­˜
            self.memory.save_context(
                {"workflow_input": workflow_input},
                {"workflow_result": result}
            )
            
            # è¾“å‡ºæœ€ç»ˆç»“æœ
            print(f"\n{'='*50}")
            print(f"ğŸ‰ å·¥ä½œæµç¨‹å®Œæˆ")
            print(f"{'='*50}")
            
            if report:
                print(report)
            
            return result
            
        except Exception as e:
            print(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            self.memory.save_context(
                {"workflow_input": workflow_input},
                {"error": str(e), "workflow_status": "failed"}
            )
            return {
                'emails_processed': 0,
                'filter_stats': {},
                'report': "",
                'workflow_status': 'failed',
                'error': str(e)
            }
    
    def run_email_only(self, days: int = 1) -> Dict[str, Any]:
        """ä»…è¿è¡Œé‚®ä»¶è·å–"""
        return self.email_chain({"days": days})
    
    def run_filter_only(self, limit: int = 50) -> Dict[str, Any]:
        """ä»…è¿è¡Œæ–‡ç« ç­›é€‰"""
        return self.filter_chain({"limit": limit})
    
    def run_report_only(self, days: int = 1) -> Dict[str, Any]:
        """ä»…è¿è¡ŒæŠ¥å‘Šç”Ÿæˆ"""
        return self.report_chain({"days": days})
    
    def get_memory_variables(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ä¸­çš„å˜é‡"""
        return self.memory.load_memory_variables({})
