"""
ç®€åŒ–çš„Langchainæ¶æ„å®ç°
é¿å…å¤æ‚çš„ä¾èµ–å†²çªï¼Œä½¿ç”¨æ ¸å¿ƒLangchainæ¦‚å¿µé‡æ„ç³»ç»Ÿ
"""
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

from openai import OpenAI
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field

from email_fetcher import EmailFetcher
from data_storage import db_manager
from config import DEEPSEEK_API_KEY, DEEPSEEK_BASE_URL, CONTENT_FILTER_PROMPT


class FilterResult(BaseModel):
    """ç­›é€‰ç»“æœæ¨¡å‹"""
    is_selected: bool = Field(description="æ˜¯å¦é€šè¿‡ç­›é€‰")
    quality_score: float = Field(description="è´¨é‡è¯„åˆ†(1-10)", ge=1, le=10)
    relevance_score: float = Field(description="ç›¸å…³æ€§è¯„åˆ†(1-10)", ge=1, le=10)
    reason: str = Field(description="ç­›é€‰ç†ç”±")
    key_points: List[str] = Field(description="å…³é”®è¦ç‚¹", default=[])
    category: str = Field(description="æ–‡ç« åˆ†ç±»", default="å…¶ä»–")


class LangchainProcessor:
    """åŸºäºLangchainçš„ç®€åŒ–å¤„ç†å™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.llm = OpenAI(
            api_key=DEEPSEEK_API_KEY,
            base_url=DEEPSEEK_BASE_URL
        )
        
        # åˆå§‹åŒ–æç¤ºæ¨¡æ¿
        self.filter_prompt = PromptTemplate(
            template=CONTENT_FILTER_PROMPT,
            input_variables=["title", "source", "summary", "publish_time", "url"]
        )
        
        # åˆå§‹åŒ–é‚®ä»¶è·å–å™¨
        self.email_fetcher = EmailFetcher()
        
        print("âœ… ç®€åŒ–Langchainå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    def fetch_emails_chain(self, days: int = 1) -> Dict[str, Any]:
        """é‚®ä»¶è·å–é“¾"""
        print(f"\nğŸ”„ æ‰§è¡Œé‚®ä»¶è·å–é“¾ (æœ€è¿‘ {days} å¤©)")
        
        try:
            # è·å–é‚®ä»¶
            alert_emails = self.email_fetcher.fetch_google_alerts(days=days)
            
            if not alert_emails:
                print("æ²¡æœ‰æ‰¾åˆ°æ–°çš„Google Alerté‚®ä»¶")
                return {"emails": [], "articles_count": 0}
            
            # å­˜å‚¨é‚®ä»¶å’Œæ–‡ç« 
            total_new_articles = 0
            stored_emails = []
            
            for email in alert_emails:
                # ä¿å­˜é‚®ä»¶
                saved_email = db_manager.save_alert_email({
                    'message_id': email.message_id,
                    'subject': email.subject,
                    'sender': email.sender,
                    'date': email.date,
                    'body_html': email.body_html,
                    'body_text': email.body_text
                })
                
                if saved_email and email.articles:
                    for article in email.articles:
                        article['email_message_id'] = email.message_id
                    
                    saved_articles = db_manager.save_articles(email.articles)
                    total_new_articles += len(saved_articles)
                    stored_emails.append(email)
            
            result = {
                "emails": stored_emails,
                "articles_count": total_new_articles
            }
            
            print(f"âœ… é‚®ä»¶è·å–å®Œæˆ: {len(stored_emails)} å°é‚®ä»¶, {total_new_articles} ç¯‡æ–°æ–‡ç« ")
            return result
            
        except Exception as e:
            print(f"âŒ é‚®ä»¶è·å–å¤±è´¥: {e}")
            return {"emails": [], "articles_count": 0}
    
    def filter_articles_chain(self, limit: int = None) -> Dict[str, Any]:
        """æ–‡ç« ç­›é€‰é“¾"""
        if limit:
            print(f"\nğŸ¤– æ‰§è¡Œæ–‡ç« ç­›é€‰é“¾ (é™åˆ¶ {limit} ç¯‡)")
        else:
            print(f"\nğŸ¤– æ‰§è¡Œæ–‡ç« ç­›é€‰é“¾ (å¤„ç†æ‰€æœ‰æœªç­›é€‰æ–‡ç« )")
        
        # è·å–æœªç­›é€‰çš„æ–‡ç« 
        unfiltered_articles = db_manager.get_unfiltered_articles(limit=limit)
        
        if not unfiltered_articles:
            print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç­›é€‰çš„æ–‡ç« ")
            return {'total': 0, 'processed': 0, 'selected': 0, 'rejected': 0, 'failed': 0}
        
        print(f"å¼€å§‹ç­›é€‰ {len(unfiltered_articles)} ç¯‡æ–‡ç« ...")
        
        stats = {
            'total': len(unfiltered_articles),
            'processed': 0,
            'selected': 0,
            'rejected': 0,
            'failed': 0
        }
        
        for i, article in enumerate(unfiltered_articles, 1):
            print(f"å¤„ç†ç¬¬ {i}/{len(unfiltered_articles)} ç¯‡: {article.title[:50]}...")
            
            try:
                # ä½¿ç”¨Langchainè¿›è¡Œç­›é€‰
                filter_result = self._filter_single_article(article)
                
                if filter_result:
                    # æ›´æ–°æ•°æ®åº“
                    success = db_manager.update_article_filter_result(article.id, filter_result)
                    if success:
                        stats['processed'] += 1
                        if filter_result.get('is_selected'):
                            stats['selected'] += 1
                            print(f"  âœ… é€šè¿‡ç­›é€‰")
                        else:
                            stats['rejected'] += 1
                            print(f"  âŒ æœªé€šè¿‡ç­›é€‰")
                    else:
                        stats['failed'] += 1
                        print(f"  âš ï¸ æ•°æ®åº“æ›´æ–°å¤±è´¥")
                else:
                    stats['failed'] += 1
                    print(f"  âŒ ç­›é€‰å¤±è´¥")
                
            except Exception as e:
                print(f"  âŒ å¤„ç†å¼‚å¸¸: {e}")
                stats['failed'] += 1
        
        print(f"\nâœ… ç­›é€‰å®Œæˆ:")
        print(f"  - æ€»è®¡: {stats['total']}")
        print(f"  - æˆåŠŸå¤„ç†: {stats['processed']}")
        print(f"  - ç­›é€‰é€šè¿‡: {stats['selected']}")
        print(f"  - ç­›é€‰æœªé€šè¿‡: {stats['rejected']}")
        print(f"  - å¤„ç†å¤±è´¥: {stats['failed']}")
        
        return stats
    
    def _filter_single_article(self, article) -> Optional[Dict]:
        """ä½¿ç”¨Langchainç­›é€‰å•ç¯‡æ–‡ç« """
        try:
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = {
                "title": article.title,
                "source": article.source or "æœªçŸ¥æ¥æº",
                "summary": article.summary or "æ— æ‘˜è¦",
                "publish_time": article.publish_time or "æœªçŸ¥æ—¶é—´",
                "url": article.url[:100] + "..." if len(article.url) > 100 else article.url
            }
            
            # ä½¿ç”¨æç¤ºæ¨¡æ¿ç”Ÿæˆå®Œæ•´æç¤º
            prompt = self.filter_prompt.format(**input_data)
            
            # è°ƒç”¨LLM
            response = self.llm.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»å†…å®¹åˆ†æå¸ˆï¼Œè´Ÿè´£è¯„ä¼°å’Œç­›é€‰æ–°é—»æ–‡ç« çš„è´¨é‡å’Œç›¸å…³æ€§ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            # è§£æå“åº”
            return self._parse_llm_response(response.choices[0].message.content)
            
        except Exception as e:
            print(f"ç­›é€‰æ–‡ç« æ—¶å‡ºé”™: {e}")
            return None
    
    def _parse_llm_response(self, response: str) -> Optional[Dict]:
        """è§£æLLMå“åº”"""
        try:
            # æŸ¥æ‰¾JSONéƒ¨åˆ†
            response = response.strip()
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_str = response[start_idx:end_idx]
                result = json.loads(json_str)
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = ['is_selected', 'quality_score', 'relevance_score', 'reason']
                if all(field in result for field in required_fields):
                    # ç¡®ä¿åˆ†æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    result['quality_score'] = max(1, min(10, float(result.get('quality_score', 5))))
                    result['relevance_score'] = max(1, min(10, float(result.get('relevance_score', 5))))
                    
                    # ç¡®ä¿åˆ—è¡¨å­—æ®µå­˜åœ¨
                    if 'key_points' not in result:
                        result['key_points'] = []
                    if 'category' not in result:
                        result['category'] = "å…¶ä»–"
                    
                    return result
                else:
                    print(f"å“åº”ç¼ºå°‘å¿…éœ€å­—æ®µ: {result}")
                    return None
            else:
                print(f"æ— æ³•æ‰¾åˆ°æœ‰æ•ˆJSON: {response}")
                return None
                
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            return None
        except Exception as e:
            print(f"è§£æå“åº”æ—¶å‡ºé”™: {e}")
            return None
    
    def generate_report_chain(self, days: int = 1) -> str:
        """æŠ¥å‘Šç”Ÿæˆé“¾"""
        print(f"\nğŸ“Š æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆé“¾ (æœ€è¿‘ {days} å¤©)")
        
        try:
            # è·å–æ•°æ®åº“ç»Ÿè®¡
            stats = db_manager.get_statistics()
            
            print(f"æ•°æ®åº“ç»Ÿè®¡:")
            print(f"  - æ€»é‚®ä»¶æ•°: {stats['total_emails']}")
            print(f"  - æ€»æ–‡ç« æ•°: {stats['total_articles']}")
            print(f"  - å·²ç­›é€‰: {stats['filtered_articles']}")
            print(f"  - ç­›é€‰é€šè¿‡: {stats['selected_articles']}")
            
            # è·å–ç­›é€‰é€šè¿‡çš„æ–‡ç« 
            selected_articles = db_manager.get_selected_articles(days=days)
            
            if not selected_articles:
                report = f"æœ€è¿‘ {days} å¤©æ²¡æœ‰ç­›é€‰é€šè¿‡çš„æ–‡ç« ã€‚"
                return report
            
            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            report = self._generate_detailed_report(selected_articles, days)
            
            print("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return report
            
        except Exception as e:
            print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def _generate_detailed_report(self, articles, days: int) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        # ç»Ÿè®¡åˆ†æ
        source_stats = {}
        category_stats = {}
        quality_scores = []
        relevance_scores = []
        
        for article in articles:
            # æ¥æºç»Ÿè®¡
            source = article.source or "æœªçŸ¥æ¥æº"
            source_stats[source] = source_stats.get(source, 0) + 1
            
            # ç±»åˆ«ç»Ÿè®¡
            if article.category:
                category_stats[article.category] = category_stats.get(article.category, 0) + 1
            
            # åˆ†æ•°æ”¶é›†
            if article.quality_score:
                quality_scores.append(article.quality_score)
            if article.relevance_score:
                relevance_scores.append(article.relevance_score)
        
        # è®¡ç®—å¹³å‡åˆ†
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        avg_relevance = sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""
æœ€è¿‘ {days} å¤©ç­›é€‰æŠ¥å‘Š (Langchainæ¶æ„)
{'='*50}

æ€»ä½“ç»Ÿè®¡:
- ç­›é€‰é€šè¿‡æ–‡ç« : {len(articles)} ç¯‡
- å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.1f}/10
- å¹³å‡ç›¸å…³æ€§è¯„åˆ†: {avg_relevance:.1f}/10

æ¥æºåˆ†å¸ƒ:
"""
        
        # æ·»åŠ æ¥æºç»Ÿè®¡
        for source, count in sorted(source_stats.items(), key=lambda x: x[1], reverse=True):
            report += f"- {source}: {count} ç¯‡\n"
        
        # æ·»åŠ ç±»åˆ«ç»Ÿè®¡
        if category_stats:
            report += "\nç±»åˆ«åˆ†å¸ƒ:\n"
            for category, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
                report += f"- {category}: {count} ç¯‡\n"
        
        # æ·»åŠ é«˜è´¨é‡æ–‡ç« æ¨è
        top_articles = sorted(articles, 
                            key=lambda x: (x.quality_score or 0) + (x.relevance_score or 0), 
                            reverse=True)[:5]
        
        if top_articles:
            report += "\næ¨èé˜…è¯» (Top 5):\n"
            for i, article in enumerate(top_articles, 1):
                report += f"{i}. {article.title}\n"
                report += f"   æ¥æº: {article.source} | è´¨é‡: {article.quality_score:.1f} | ç›¸å…³æ€§: {article.relevance_score:.1f}\n"
                report += f"   é“¾æ¥: {article.url}\n\n"
        
        return report
    
    def run_full_workflow(self, days: int = 1, filter_limit: int = None, auto_export_excel: bool = True) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„Langchainå·¥ä½œæµç¨‹"""
        print(f"ğŸš€ å¯åŠ¨Langchainæ–°é—»å¤„ç†å·¥ä½œæµ")
        print(f"ğŸ“… å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # æ­¥éª¤1: é‚®ä»¶è·å–é“¾
            email_result = self.fetch_emails_chain(days=days)
            
            # æ­¥éª¤2: æ–‡ç« ç­›é€‰é“¾
            filter_result = self.filter_articles_chain(limit=filter_limit)
            
            # æ­¥éª¤3: æŠ¥å‘Šç”Ÿæˆé“¾
            report = self.generate_report_chain(days=days)
            
            # æ­¥éª¤4: è‡ªåŠ¨å¯¼å‡ºExcel (å¦‚æœå¯ç”¨)
            excel_file = ""
            if auto_export_excel:
                excel_file = self._auto_export_excel()
            
            # ç»„åˆç»“æœ
            result = {
                'emails_processed': len(email_result["emails"]),
                'articles_added': email_result["articles_count"],
                'filter_stats': filter_result,
                'report': report,
                'excel_file': excel_file,
                'workflow_status': 'completed',
                'architecture': 'langchain'
            }
            
            # è¾“å‡ºæœ€ç»ˆç»“æœ
            print(f"\n{'='*50}")
            print(f"ğŸ‰ Langchainå·¥ä½œæµç¨‹å®Œæˆ")
            print(f"{'='*50}")
            
            if report:
                print(report)
            
            if excel_file:
                print(f"\nğŸ“Š å·²è‡ªåŠ¨å¯¼å‡ºå½“æ—¥Excelæ–‡ä»¶: {excel_file}")
            
            return result
            
        except Exception as e:
            print(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'emails_processed': 0,
                'articles_added': 0,
                'filter_stats': {},
                'report': "",
                'excel_file': "",
                'workflow_status': 'failed',
                'error': str(e),
                'architecture': 'langchain'
            }
    
    def _auto_export_excel(self) -> str:
        """è‡ªåŠ¨å¯¼å‡ºå½“å¤©çš„Excelæ–‡ä»¶"""
        try:
            print(f"\nğŸ“Š è‡ªåŠ¨å¯¼å‡ºå½“æ—¥Excelæ–‡ä»¶...")
            
            # å¯¼å…¥excel_exporter
            from excel_exporter import excel_exporter
            
            # å¯¼å‡ºä»Šå¤©çš„æ•°æ® (1å¤©)
            excel_file = excel_exporter.export_selected_articles(days=1)
            
            if excel_file:
                print(f"âœ… Excelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_file}")
                return excel_file
            else:
                print("âš ï¸ ä»Šå¤©æ²¡æœ‰ç­›é€‰é€šè¿‡çš„æ–‡ç« ï¼Œæœªç”ŸæˆExcelæ–‡ä»¶")
                return ""
                
        except Exception as e:
            print(f"âŒ Excelå¯¼å‡ºå¤±è´¥: {e}")
            return ""


if __name__ == "__main__":
    # æµ‹è¯•ç®€åŒ–Langchainå¤„ç†å™¨
    if not DEEPSEEK_API_KEY:
        print("è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        exit(1)
    
    try:
        print("ğŸ§ª æµ‹è¯•ç®€åŒ–Langchainæ¶æ„...")
        
        processor = LangchainProcessor()
        
        # æµ‹è¯•å®Œæ•´å·¥ä½œæµ
        result = processor.run_full_workflow(days=1, filter_limit=3)
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")
        print(f"æ¶æ„: {result.get('architecture', 'unknown')}")
        print(f"çŠ¶æ€: {result.get('workflow_status', 'unknown')}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
